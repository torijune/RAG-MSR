############## ì´ˆê¸° ì¿¼ë¦¬ ############
import json
import random
import pandas as pd

def load_queries_jsonl(path):
    with open(path, "r", encoding="utf-8") as f:
        return [json.loads(line) for line in f]

def initial_query():
    queries = load_queries_jsonl("datasets/nfcorpus/nfcorpus_raw/queries.jsonl")
    sampled = random.sample(queries, 3)
    return {q["_id"]: q["text"] for q in sampled}

def get_test_queries(number):
    test_file_path = "datasets/nfcorpus/nfcorpus_raw/qrels/test.tsv"
    query_file_path = "datasets/nfcorpus/nfcorpus_raw/queries.jsonl"

    df_test = pd.read_csv(test_file_path, sep="\t")
    queries = load_queries_jsonl(query_file_path)
    # test_query_id = df_test['query-id']
    # test_answer_id  = df_test['corpus-id']

    test_query_ids = df_test['query-id'].unique().tolist()

    test_query = {q["_id"]: q["text"] for q in queries if q["_id"] in test_query_ids}
    if number == 'all':
        test_query = {q["_id"]: q["text"] for q in queries if q["_id"] in test_query_ids}
    else :
        test_query = dict(list(test_query.items())[:str(number)])
    return test_query

def get_queries_by_ids(query_ids):
    query_file_path = "datasets/nfcorpus/nfcorpus_raw/queries.jsonl"
    queries = load_queries_jsonl(query_file_path)

    selected_queries = {q["_id"]: q["text"] for q in queries if q["_id"] in query_ids}
    return selected_queries


############ GenCRF Reformulation Prompts ############

'''
- Contextual Expansion:
    - ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ë¥¼ íŒŒì•…í•œ í›„, ë¬¸ë§¥ì„ í™•ì¥í•˜ì—¬ ë” í’ë¶€í•œ ì •ë³´ë¥¼ ì œê³µ
    - ì§ˆë¬¸ì˜ ë¬¸ë§¥ì„ ë„“í˜€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë” í™•ì¥í•˜ëŠ” ë°©ì‹
- Detail Specific:
    - ì§ˆë¬¸ì˜ êµ¬ì²´ì ì¸ ì„¸ë¶€ ì‚¬í•­ì´ë‚˜ í•˜ìœ„ ì£¼ì œì— ì´ˆì ì„ ë§ì¶° ë‹µë³€ì„ ìƒì„±
    - ì§ˆë¬¸ì˜ íŠ¹ì • ë¶€ë¶„ì— ëŒ€í•´ ê¹Šì´ ìˆëŠ” ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë°©ì‹
- Aspect Specific:
    - íŠ¹ì • ì£¼ì œì˜ í•œ ì¸¡ë©´ì´ë‚˜ ì°¨ì›ì— ì§‘ì¤‘í•˜ì—¬ ì¿¼ë¦¬ë¥¼ í™•ì¥í•˜ëŠ” ë°©ì‹
    - ì£¼ì œì˜ íŠ¹ì • ì¸¡ë©´ì— ëŒ€í•´ ë” êµ¬ì²´ì ì´ê³  í’ë¶€í•œ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆë„ë¡ ë„ì›€
'''

def ContextualExpansion(query):
    prompt = f"""
    You are a contextual expansion expert. Your task is to understand the core intent of the original query and provide a refined, contextually expanded answer within 100 characters.
    Below is the query: {query}
    """
    return prompt

def DetailSpecific(query):
    prompt = f"""
    You are a detail-specific expert. Your task is to understand the core intent of the original query and provide a refined, detailed answer focusing on particular details or subtopics within 100 characters.
    Below is the query: {query}
    """
    return prompt

def GenCRF_AspectSpecific(query):
    prompt = f"""
    You are an aspect-specific inquiry expert. Your task is to provide a refined answer focusing on a specific aspect or dimension within 100 characters.
    Below is the query: {query}
    """
    return prompt

############ RAG-MSR Reformulation Prompt ############

'''
- Paraphrasing:
    - ì¿¼ë¦¬ë¥¼ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ë˜ ì˜ë¯¸ëŠ” ë™ì¼í•˜ê²Œ ìœ ì§€
    - ë‹¤ì–‘í•œ í‘œí˜„ì„ í†µí•´ ê²€ìƒ‰ ë‹¤ì–‘ì„±ì„ ë†’ì´ëŠ” ë° ìœ ë¦¬
- AspectSpecific:
    - íŠ¹ì • ì¸¡ë©´(ì˜ˆ: ë¹„ìš©, ì„±ëŠ¥, ì‚¬ìš©ì„± ë“±)ì— ì´ˆì ì„ ë§ì¶° ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±
    - ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì¢í˜€ ë” ì •ë°€í•œ ì •ë³´ë¥¼ ì–»ê³ ì í•  ë•Œ ìœ ìš©
- EntityAware:
    - ì¿¼ë¦¬ì— ì‚¬ëŒ, ì¥ì†Œ, ë„êµ¬, ì´ë²¤íŠ¸ ë“± ëª…ì‹œì  ì—”í‹°í‹°ë¥¼ í¬í•¨ì‹œì¼œ ì¬ì‘ì„±
    - ê²€ìƒ‰ ì‹œìŠ¤í…œì˜ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë° íš¨ê³¼ì 
'''

# ë¬¸ì¥ì´ ë„ˆë¬´ ì§§ì„ë•ŒëŠ” í•´ê²°í•˜ê¸° ìœ„í•´ ì¶”ê°€
input_query_type_rule = """
Analyze the given query and determine its characteristics.

Depending on the query type, decide the most effective reformulation strategy for improving retrieval accuracy.

Consider:
- If the query is too short or keyword-based 
    â†’ Expand into a natural language question with background context and the reformulation rule.
- If the query is already a full sentence 
    â†’ Follow the reformulation rule below to refine a full sentence.
"""

output_rule = """
Output Rules:
- Do not explain your strategy.
- Only output the final reformulated query within 100 characters .
"""

# Group_1
def Paraphrasing(query):
    prompt = f"""
    You are a paraphrasing expert. 

    Your task is to rewrite the original query in a new way using different wording but maintaining the same meaning. 
    Original Query: {query}
    """
    return prompt

def RAG_MSR_AspectSpecific(query):
    prompt = f"""
    You are an aspect-specific reformulation expert. 

    - Reformulation Rule:
        Your task is to rewrite the query focusing on one specific dimension (e.g., cost, usability, performance, user experience). 
    Original Query: {query}
    """
    return prompt

def EntityAware(query):
    prompt = f"""
    You are an entity-aware reformulation expert. 
    - Reformulation Rule:
        Rewrite the query by incorporating specific entities (e.g., people, places, tools, events) to improve retrieval accuracy. 

    Original Query: {query}
    """
    return prompt


# Group_2
def Clarification_Reformulation(query):
    prompt = f"""You are an expert search assistant.
    {input_query_type_rule}

    - Reformulation Rule: 
        Rewrite the query to clarify intent, resolve ambiguity, and add necessary context.
    {output_rule}

    Original Query: "{query}"
    """
    return prompt


def EntityExpansion_Reformulation(query):
    prompt = f"""You are an expert in query expansion.
    {input_query_type_rule}

    - Reformulation Rule:   
        Rewrite the query by adding important entities, keywords, or related concepts to improve retrieval performance.
    {output_rule}

    Original Query: "{query}"
    """
    return prompt


def RetrievalCondense_Reformulation(query):
    prompt = f"""You are an expert in information retrieval optimization.
    {input_query_type_rule}

    - Reformulation Rule: 
        Rewrite the query in a concise, document-friendly style suitable for retrieval, preserving only essential keywords.
    {output_rule}

    Original Query: "{query}"
    """
    return prompt

########## RAG-MSR LLM Scoring Prompts ########

'''
LLM Scoring í”„ë¡¬í”„íŠ¸
LLM Scoringì€ ê° í´ëŸ¬ìŠ¤í„°ì˜ ì¿¼ë¦¬ë“¤ì„ í‰ê°€í•˜ì—¬ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì…ë‹ˆë‹¤.
ê´€ë ¨ì„±, êµ¬ì²´ì„±, ëª…í™•ì„±, í¬ê´„ì„±, ìœ ìš©ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
'''

def LLMScoring(q_init, rerank_queries):
    # q_initëŠ” ê·¸ëƒ¥ ì¿¼ë¦¬, rerank_queriesëŠ” ë¦¬ë­í‚¹ëœ ë¬¸ì„œ ì§‘í•©(ë”•ì…”ë„ˆë¦¬)
    formatted_docs = "\n".join([f"Doc{i+1}: {doc}" for i, doc in enumerate(rerank_queries)])
    prompt = f"""
    You are an expert in information retrieval evaluation. Your task is to score each reranked document based on how well it addresses the user's original question. Consider the following aspects:

    - Relevance to the user's intent
    - Clarity and usefulness of the content
    - Completeness and specificity of the answer
    - Overall alignment with the original query

    Assign a score from 0 to 100 for each document. A document that fully addresses the question in a clear and specific way should receive a high score (90â€“100), while a document that is vague, irrelevant, or only partially related should score lower.

    Only return the scores in the following list format:
    [score_doc1, score_doc2, score_doc3, score_doc4, score_doc5]

    Original Query: {q_init}
    Reranked Documents:
    {formatted_docs}
    """
    return prompt


########## RAG-MSR Reformulationìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆëŠ” ê¸°ì¡´ í•œê³„ì  ##########

'''
ğŸ” ê¸°ì¡´ RAG ê¸°ë°˜ ì—°êµ¬ì˜ í•œê³„ì 
	1.	ì¬ì§ˆë¬¸(Query)ì˜ ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•´ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ í¸í–¥ë  ìˆ˜ ìˆìŒ
	2.	ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ëª¨í˜¸í•˜ê±°ë‚˜ ê´‘ë²”ìœ„í•  ê²½ìš° ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨ ê°€ëŠ¥ì„±
	3.	ì •í™•í•œ ì •ë³´ ê²€ìƒ‰ë³´ë‹¤ ë‹¨ìˆœ ì—°ê´€ í‚¤ì›Œë“œ ë§¤ì¹­ì— ì˜ì¡´
	4.	ëª…í™•í•œ ì˜ë„ íŒŒì•… ì—†ì´ ë¬¸ë§¥ì„ í™•ì¥í•´ ë²„ë ¤ irrelevantí•œ ë¬¸ì„œê°€ ì„ íƒë¨
	5.	ë‹¨ì¼ ì§ˆì˜ë¡œ ì¸í•´ ë‹¤ì–‘í•œ ê´€ì ì˜ ì •ë³´ íƒìƒ‰ ë¶€ì¡±

âœ… RAG-MSR í”„ë¡¬í”„íŠ¸ë“¤ì´ í•´ê²°í•˜ëŠ” ë°©ì‹
- Paraphrasing:
    - 1. ì§ˆì˜ ë‹¤ì–‘ì„± ë¶€ì¡± í•´ê²°
- AspectSpecific: 
    - 2,3,5. í¬ê´„ì  ì¿¼ë¦¬ì—ì„œ íŠ¹ì • ì¸¡ë©´ì— ì§‘ì¤‘í•˜ì—¬ ì´ˆì  ìˆëŠ” ì¿¼ë¦¬ë¡œ ì¬êµ¬ì„±
- EntityAware: 
    - 2,4,5. ë¬¸ë§¥ ë¶€ì¡± ë¬¸ì œë¥¼ ëª…ì‹œì  entityë¥¼ ë„£ìŒìœ¼ë¡œì¨ ê°œì„ 
'''